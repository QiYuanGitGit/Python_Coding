{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Library"
      ],
      "metadata": {
        "id": "MaZW9SqlR4kf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZUfEuJ7HQv_R"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET #XML.file\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#File paths"
      ],
      "metadata": {
        "id": "lUeqtMuISCiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_file = \"log_file.txt\"\n",
        "target_file = \"transformed_data.csv\""
      ],
      "metadata": {
        "id": "sgdD9y--R6Ov"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extraction (**E**)"
      ],
      "metadata": {
        "id": "rLCcp8_xSIr9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####CSV"
      ],
      "metadata": {
        "id": "u4lpui7RZcbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_from_csv(file_to_process):\n",
        "    dataframe = pd.read_csv(file_to_process)\n",
        "    return dataframe"
      ],
      "metadata": {
        "id": "R5crlLSOSSPK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####JSON"
      ],
      "metadata": {
        "id": "cD5Qm49mZeQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_from_json(file_to_process):\n",
        "    dataframe = pd.read_json(file_to_process, lines=True)\n",
        "    return dataframe"
      ],
      "metadata": {
        "id": "wLuBmuomZXnl"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####XML"
      ],
      "metadata": {
        "id": "87AYXVUyZfwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_from_xml(file_to_process):\n",
        "    dataframe = pd.DataFrame(columns=[\"name\", \"height\", \"weight\"])\n",
        "    tree = ET.parse(file_to_process)\n",
        "    root = tree.getroot()\n",
        "    for person in root:\n",
        "        name = person.find(\"name\").text\n",
        "        height = float(person.find(\"height\").text)\n",
        "        weight = float(person.find(\"weight\").text)\n",
        "        dataframe = pd.concat([dataframe, pd.DataFrame([{\"name\":name, \"height\":height, \"weight\":weight}])], ignore_index=True)\n",
        "    return dataframe"
      ],
      "metadata": {
        "id": "o_29RCbOZZRc"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to identify which function to call on basis of the filetype of the data file. To call the relevant function, write a function extract, which uses the glob library to identify the filetype:"
      ],
      "metadata": {
        "id": "ojXLS9EIZzOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract():\n",
        "    extracted_data = pd.DataFrame(columns=['name','height','weight']) # create an empty data frame to hold extracted data\n",
        "\n",
        "    # process all csv files, except the target file\n",
        "    for csvfile in glob.glob(\"*.csv\"):\n",
        "        if csvfile != target_file:  # check if the file is not the target file\n",
        "            extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_csv(csvfile))], ignore_index=True)\n",
        "\n",
        "    # process all json files\n",
        "    for jsonfile in glob.glob(\"*.json\"):\n",
        "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_json(jsonfile))], ignore_index=True)\n",
        "\n",
        "    # process all xml files\n",
        "    for xmlfile in glob.glob(\"*.xml\"):\n",
        "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_xml(xmlfile))], ignore_index=True)\n",
        "\n",
        "    return extracted_data"
      ],
      "metadata": {
        "id": "EdLHP00MZaLP"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transformation(T)"
      ],
      "metadata": {
        "id": "UWu1WDQ1Z4oR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Task2: Transformation\n",
        "def transform(data):\n",
        "    '''Convert inches to meters and round off to two decimals\n",
        "    1 inch is 0.0254 meters '''\n",
        "    data['height'] = round(data.height * 0.0254,2)\n",
        "\n",
        "    '''Convert pounds to kilograms and round off to two decimals\n",
        "    1 pound is 0.45359237 kilograms '''\n",
        "    data['weight'] = round(data.weight * 0.45359237,2)\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "Ypr--YFUZxIa"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading and Logging(L)"
      ],
      "metadata": {
        "id": "yDfhuNwTZ9vm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(target_file, transformed_data):\n",
        "    transformed_data.to_csv(target_file)\n",
        "\n",
        "def log_progress(message):\n",
        "    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second\n",
        "    now = datetime.now() # get current timestamp\n",
        "    timestamp = now.strftime(timestamp_format)\n",
        "    with open(log_file,\"a\") as f:\n",
        "        f.write(timestamp + ',' + message + '\\n')"
      ],
      "metadata": {
        "id": "xX9dVqWuZ9AX"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Log the initialization of the ETL process\n",
        "log_progress(\"ETL Job Started\")\n",
        "\n",
        "# Log the beginning of the Extraction process\n",
        "log_progress(\"Extract phase Started\")\n",
        "extracted_data = extract()\n",
        "\n",
        "# Log the completion of the Extraction process\n",
        "log_progress(\"Extract phase Ended\")\n",
        "\n",
        "# Log the beginning of the Transformation process\n",
        "log_progress(\"Transform phase Started\")\n",
        "transformed_data = transform(extracted_data)\n",
        "print(\"Transformed Data\")\n",
        "print(transformed_data)\n",
        "\n",
        "# Log the completion of the Transformation process\n",
        "log_progress(\"Transform phase Ended\")\n",
        "\n",
        "# Log the beginning of the Loading process\n",
        "log_progress(\"Load phase Started\")\n",
        "load_data(target_file,transformed_data)\n",
        "\n",
        "# Log the completion of the Loading process\n",
        "log_progress(\"Load phase Ended\")\n",
        "\n",
        "# Log the completion of the ETL process\n",
        "log_progress(\"ETL Job Ended\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oIw0AD0jaPQi",
        "outputId": "91e44f14-baa7-49ab-da69-777144803b05"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[21], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Log the beginning of the Extraction process \u001b[39;00m\n\u001b[1;32m      5\u001b[0m log_progress(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtract phase Started\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m----> 6\u001b[0m extracted_data \u001b[38;5;241m=\u001b[39m extract() \n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Log the completion of the Extraction process \u001b[39;00m\n\u001b[1;32m      9\u001b[0m log_progress(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtract phase Ended\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n",
            "Cell \u001b[0;32mIn[18], line 7\u001b[0m, in \u001b[0;36mextract\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m csvfile \u001b[38;5;129;01min\u001b[39;00m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m): \n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m csvfile \u001b[38;5;241m!=\u001b[39m target_file:  \u001b[38;5;66;03m# check if the file is not the target file\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m         extracted_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([extracted_data, pd\u001b[38;5;241m.\u001b[39mDataFrame(extract_from_csv(csvfile))], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# process all json files \u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m jsonfile \u001b[38;5;129;01min\u001b[39;00m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.json\u001b[39m\u001b[38;5;124m\"\u001b[39m): \n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/reshape/concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    383\u001b[0m     objs,\n\u001b[1;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    393\u001b[0m )\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/reshape/concat.py:684\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    680\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[1;32m    682\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[0;32m--> 684\u001b[0m new_data \u001b[38;5;241m=\u001b[39m concatenate_managers(\n\u001b[1;32m    685\u001b[0m     mgrs_indexers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_axes, concat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbm_axis, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m    686\u001b[0m )\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    688\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/concat.py:189\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m    187\u001b[0m     fastpath \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m values\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 189\u001b[0m     values \u001b[38;5;241m=\u001b[39m _concatenate_join_units(join_units, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    190\u001b[0m     fastpath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fastpath:\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/concat.py:486\u001b[0m, in \u001b[0;36m_concatenate_join_units\u001b[0;34m(join_units, copy)\u001b[0m\n\u001b[1;32m    483\u001b[0m     concat_values \u001b[38;5;241m=\u001b[39m ensure_block_shape(concat_values, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     concat_values \u001b[38;5;241m=\u001b[39m concat_compat(to_concat, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m empty_dtype \u001b[38;5;241m!=\u001b[39m empty_dtype_future:\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m empty_dtype \u001b[38;5;241m==\u001b[39m concat_values\u001b[38;5;241m.\u001b[39mdtype:\n\u001b[1;32m    490\u001b[0m         \u001b[38;5;66;03m# GH#39122, GH#40893\u001b[39;00m\n",
            "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/dtypes/concat.py:78\u001b[0m, in \u001b[0;36mconcat_compat\u001b[0;34m(to_concat, axis, ea_compat_axis)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m     77\u001b[0m     to_concat_arrs \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSequence[np.ndarray]\u001b[39m\u001b[38;5;124m\"\u001b[39m, to_concat)\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mconcatenate(to_concat_arrs, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m     80\u001b[0m to_concat_eas \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSequence[ExtensionArray]\u001b[39m\u001b[38;5;124m\"\u001b[39m, to_concat)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ea_compat_axis:\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# We have 1D objects, that don't support axis keyword\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exepected Output:\n",
        "\n",
        "Transformed Data\n",
        "     name  height  weight\n",
        "0    alex    1.67   51.25\n",
        "1    ajay    1.82   61.91\n",
        "2   alice    1.76   69.41\n",
        "3    ravi    1.73   64.56\n",
        "4     joe    1.72   65.45\n",
        "5    alex    1.67   51.25\n",
        "6    ajay    1.82   61.91\n",
        "7   alice    1.76   69.41\n",
        "8    ravi    1.73   64.56\n",
        "9     joe    1.72   65.45\n",
        "10   alex    1.67   51.25\n",
        "11   ajay    1.82   61.91\n",
        "12  alice    1.76   69.41\n",
        "13   ravi    1.73   64.56\n",
        "14    joe    1.72   65.45\n",
        "15   jack    1.74   55.93\n",
        "16    tom    1.77   64.18\n",
        "17  tracy    1.78   61.90\n",
        "18   john    1.72   50.97\n",
        "19   jack    1.74   55.93\n",
        "20    tom    1.77   64.18\n",
        "21  tracy    1.78   61.90\n",
        "22   john    1.72   50.97\n",
        "23   jack    1.74   55.93\n",
        "24    tom    1.77   64.18\n",
        "25  tracy    1.78   61.90\n",
        "26   john    1.72   50.97\n",
        "27  simon    1.72   50.97\n",
        "28  jacob    1.70   54.73\n",
        "29  cindy    1.69   57.81\n",
        "30   ivan    1.72   51.77\n",
        "31  simon    1.72   50.97\n",
        "32  jacob    1.70   54.73\n",
        "33  cindy    1.69   57.81\n",
        "34   ivan    1.72   51.77\n",
        "35  simon    1.72   50.97\n",
        "36  jacob    1.70   54.73\n",
        "37  cindy    1.69   57.81\n",
        "38   ivan    1.72   51.77\n"
      ],
      "metadata": {
        "id": "RCEOIX9KbVAP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9C95c72QbXx5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}